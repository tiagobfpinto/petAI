"""empty message

Revision ID: 7c4f4978ff9d
Revises: a679b42fd930
Create Date: 2025-12-14 17:32:03.621193

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = '7c4f4978ff9d'
down_revision = 'a679b42fd930'
branch_labels = None
depends_on = None


def _table_exists(inspector, table_name: str) -> bool:
    return table_name in inspector.get_table_names()


def _index_exists(inspector, table_name: str, index_name: str) -> bool:
    return any(index["name"] == index_name for index in inspector.get_indexes(table_name))


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    bind = op.get_bind()
    inspector = sa.inspect(bind)

    if not _table_exists(inspector, 'Item'):
        op.create_table('Item',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('name', sa.String(), nullable=False),
        sa.Column('type', sa.String(), nullable=False),
        sa.Column('default_source', sa.String(), nullable=True),
        sa.Column('value', sa.Integer(), nullable=True),
        sa.Column('rarity', sa.String(), nullable=True),
        sa.Column('trigger', sa.String(), nullable=True),
        sa.PrimaryKeyConstraint('id')
        )

    if not _table_exists(inspector, 'ItemTransaction'):
        op.create_table('ItemTransaction',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('item_id', sa.Integer(), nullable=False),
        sa.Column('valu', sa.Integer(), nullable=False),
        sa.Column('op', sa.String(), nullable=False),
        sa.Column('currency', sa.String(), nullable=False),
        sa.Column('date', sa.DateTime(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(['item_id'], ['Item.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
        )

    if not _table_exists(inspector, 'itemsOwnership'):
        op.create_table('itemsOwnership',
        sa.Column('id', sa.Integer(), nullable=False),
        sa.Column('user_id', sa.Integer(), nullable=False),
        sa.Column('item_id', sa.Integer(), nullable=False),
        sa.Column('pet_id', sa.Integer(), nullable=True),
        sa.Column('acquired_at', sa.DateTime(timezone=True), nullable=False),
        sa.ForeignKeyConstraint(['item_id'], ['Item.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['pet_id'], ['pets.id'], ondelete='CASCADE'),
        sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
        sa.PrimaryKeyConstraint('id')
        )
        with op.batch_alter_table('itemsOwnership', schema=None) as batch_op:
            batch_op.create_index(batch_op.f('ix_itemsOwnership_pet_id'), ['pet_id'], unique=False)
            batch_op.create_index(batch_op.f('ix_itemsOwnership_user_id'), ['user_id'], unique=False)
    else:
        pet_index = op.f('ix_itemsOwnership_pet_id')
        user_index = op.f('ix_itemsOwnership_user_id')
        if not _index_exists(inspector, 'itemsOwnership', pet_index):
            with op.batch_alter_table('itemsOwnership', schema=None) as batch_op:
                batch_op.create_index(pet_index, ['pet_id'], unique=False)
        if not _index_exists(inspector, 'itemsOwnership', user_index):
            with op.batch_alter_table('itemsOwnership', schema=None) as batch_op:
                batch_op.create_index(user_index, ['user_id'], unique=False)

    if _table_exists(inspector, 'items'):
        pet_index = 'ix_items_pet_id'
        user_index = 'ix_items_user_id'
        with op.batch_alter_table('items', schema=None) as batch_op:
            if _index_exists(inspector, 'items', pet_index):
                batch_op.drop_index(pet_index)
            if _index_exists(inspector, 'items', user_index):
                batch_op.drop_index(user_index)

        op.drop_table('items')
    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('items',
    sa.Column('id', sa.INTEGER(), autoincrement=True, nullable=False),
    sa.Column('user_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('pet_id', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('acquired_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=False),
    sa.Column('equiped', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('trigger', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('rarity', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('value', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['pet_id'], ['pets.id'], name='items_pet_id_fkey', ondelete='CASCADE'),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='items_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='items_pkey')
    )
    with op.batch_alter_table('items', schema=None) as batch_op:
        batch_op.create_index('ix_items_user_id', ['user_id'], unique=False)
        batch_op.create_index('ix_items_pet_id', ['pet_id'], unique=False)

    with op.batch_alter_table('itemsOwnership', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_itemsOwnership_user_id'))
        batch_op.drop_index(batch_op.f('ix_itemsOwnership_pet_id'))

    op.drop_table('itemsOwnership')
    op.drop_table('ItemTransaction')
    op.drop_table('Item')
    # ### end Alembic commands ###
